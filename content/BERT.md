BERT（Bidirectional Encoder Representations from Transformers）是由 [[Google]] 在 2018 年发布的一种自然语言处理（NLP）模型。所以它是早于 [[GPT]] 的。

BERT 是 Encoder-Only 的，所以不擅长生成，而擅长分析。
